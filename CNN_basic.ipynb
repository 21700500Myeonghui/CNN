{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.init as init\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "batch_size = 256\n",
    "learning_rate = 0.0002\n",
    "num_epoch = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<body>\n",
    "train 인수 : True면 학습 데이터를 불러오고 False면 테스트 데이터를 불러온다.<br>\n",
    "transform 인수 : 데이터에 대한 변형<br>\n",
    "target_transform : 라벨에 대한 변형<br>\n",
    "download : 현재 경로에 MINST 데이터가 없을 경우에 다운로드하겠다.<br>\n",
    "</body>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_train = dset.MNIST(\"./\",train=True,transform = transforms.ToTensor(),target_transform=None,download=True)\n",
    "mnist_test = dset.MNIST(\"./\",train = False, transform = transforms.ToTensor(), target_transform = None,download=True)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(mnist_train,batch_size=batch_size,shuffle=True,num_workers=2,drop_last=True)\n",
    "#num_worker : 데이터를 묶을 때 사용할 프로세스의 갯수\n",
    "#drop_last : 묶고 남는 데이터는 버릴지 여부\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(mnist_test,batch_size=batch_size,shuffle=False,num_workers=2,drop_last=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 4, 2, 2, 6, 1, 1, 1, 2, 3, 8, 4, 0, 0, 3, 0, 1, 7, 5, 9, 1, 0, 0, 8,\n",
      "        1, 7, 7, 7, 3, 2, 0, 2, 6, 3, 5, 4, 9, 2, 7, 0, 7, 7, 7, 8, 4, 3, 4, 6,\n",
      "        6, 7, 7, 7, 3, 7, 0, 4, 2, 9, 3, 6, 4, 9, 0, 6, 5, 4, 4, 5, 8, 5, 2, 0,\n",
      "        3, 5, 9, 3, 9, 3, 3, 9, 5, 0, 7, 9, 8, 8, 6, 7, 4, 4, 6, 8, 6, 8, 3, 0,\n",
      "        2, 6, 0, 9, 6, 8, 0, 7, 8, 1, 8, 6, 0, 8, 7, 1, 7, 9, 2, 4, 9, 8, 9, 2,\n",
      "        7, 8, 9, 8, 3, 6, 8, 4, 0, 7, 5, 0, 4, 2, 7, 4, 0, 9, 4, 3, 2, 1, 0, 9,\n",
      "        7, 4, 9, 7, 7, 3, 7, 5, 4, 3, 8, 0, 0, 9, 0, 3, 5, 0, 7, 9, 1, 9, 8, 4,\n",
      "        3, 7, 3, 1, 5, 0, 7, 9, 7, 5, 8, 8, 2, 1, 0, 9, 4, 2, 7, 7, 0, 2, 6, 3,\n",
      "        3, 1, 6, 4, 3, 9, 8, 7, 7, 3, 9, 5, 2, 9, 1, 7, 9, 1, 6, 6, 3, 2, 3, 1,\n",
      "        7, 0, 2, 4, 7, 4, 2, 9, 7, 7, 9, 1, 3, 8, 5, 6, 9, 0, 7, 0, 8, 6, 9, 1,\n",
      "        0, 9, 9, 7, 9, 0, 4, 3, 1, 1, 9, 6, 8, 1, 5, 3])\n"
     ]
    }
   ],
   "source": [
    "for j,[image,label] in enumerate(train_loader):\n",
    "    print(label)\n",
    "    if j == 0:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>CNN모델</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN,self).__init__() #CNN의 부모 클래스인 nn.Module을 초기화하는 역할\n",
    "        self.layer = nn.Sequential(\n",
    "            nn.Conv2d(1,16,5),#5는 임의로 그냥 설정하였음.\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(16,32,5),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2,2),#kernel_size: 풀링 연산 할 때 한번에 훑는 영역의 크기, #stride, #padding\n",
    "            nn.Conv2d(32,64,5),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2,2),#output size: [batch_size,64,6,6]\n",
    "        )\n",
    "        self.fc_layer = nn.Sequential(\n",
    "            nn.Linear(64*3*3,100),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(100,10)#output size : [batch_size,10]\n",
    "        )\n",
    "        \n",
    "    def forward(self,x):#연산을 순차적으로 실행하여 결괏값만 리턴하도록 정의\n",
    "        out = self.layer(x)\n",
    "        out = out.view(batch_size,-1)\n",
    "        out = self.fc_layer(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>모델 초기화와 손실함수 지정과 optimizer지정</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = CNN().to(device) #모델을 올려줌\n",
    "loss_func = nn.CrossEntropyLoss()#classification에서는 crossentorpy loss function을 사용하는 게 좋음\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=learning_rate)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.3037, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3051, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1057, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0996, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1163, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "loss_arr = []\n",
    "for i in range(num_epoch):\n",
    "   \n",
    "    for j,[image,label] in enumerate(train_loader):\n",
    "        x = image.to(device)\n",
    "        y_ = label.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        output = model.forward(x)\n",
    "        loss = loss_func(output,y_)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if j%1000==0:\n",
    "            print(loss)\n",
    "            loss_arr.append(loss.cpu().detach().numpy())#텐서에 대한 히스토리 추적을 중지하려면 .detach()를 호출하여 현재의 계산 기록으로부터 분리시키고 이후에 일어나는 계산들은 추적되지 않게 할 수 있음.\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>모델을 테스트 데이터에 대해 검증</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.max() : https://wingnim.tistory.com/34\n",
    "#torch.max 함수는 주어진 텐서 배열의 최대 값이 들어있는 index를 리턴하는 함수입니다.\n",
    "#Y_pred = [ [0.3,0.2,0.9,0.1] ] 의 경우 torch.max(Y_pred.data , 1 ) 의 결과는 0.9의 인덱스인 2가 됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#초기화 해줌.\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for image,label in test_loader:\n",
    "        x = image.to(device)\n",
    "        y_ = label.to(device)\n",
    "        \n",
    "        output = model.forward(x)\n",
    "        _,output_index = torch.max(output,1)\n",
    "        \n",
    "        total += label.size(0)#batch\n",
    "        correct += (ouput_idex==y_).sum().float()\n",
    "        \n",
    "    print(\"Accuracy of Test Data: {}\".format(100*correct/total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
